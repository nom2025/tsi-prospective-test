# 地震データ自動取得プロジェクト

地震データを自動取得し、CSVファイルに追加するスクリプトです。

## 📁 フォルダ構成

```
データ自動取得/
├── src/                          # ソースファイル
│   ├── fetch_earthquake_data.py      # 国内地震データ取得
│   ├── fetch_world_earthquake_data.py # 世界地震データ取得
│   ├── fetch_depth_data.py           # 深さデータ取得
│   └── fetch_gnss_data.py            # GNSSデータ取得
├── data/                         # データファイル
│   ├── 2010-all.csv                  # 国内地震データ（自動更新）
│   ├── world-all.csv                 # 世界地震データ（自動更新）
│   └── depth.csv                     # 深さデータ（自動更新）
├── debug/                        # デバッグファイル
│   └── debug_html_*.html             # HTMLデバッグファイル
├── YYYYMMDD/                     # 作業フォルダ（日付別）
│   ├── *_backup_*.csv                # バックアップファイル
│   └── *_new_data_*.csv              # 新規取得データのログ
├── README.md                      # このファイル
├── organize_files.py              # ファイル整理スクリプト
└── update_paths.py                # パス更新スクリプト
```

## スクリプト一覧

### 1. 国内地震データ取得 (`src/fetch_earthquake_data.py`)
Yahoo!天気・災害から地震データを自動取得し、`data/2010-all.csv`に追加します。

### 2. 世界地震データ取得 (`src/fetch_world_earthquake_data.py`)
USGS Earthquake Catalog APIから世界地震データを自動取得し、`data/world-all.csv`に追加します。

### 3. 深さデータ取得 (`src/fetch_depth_data.py`)
F-net（防災科研）から深さデータを自動取得し、`data/depth.csv`に追加します。

### 4. GNSSデータ取得 (`src/fetch_gnss_data.py`)
国土地理院GEONETからGNSSデータを自動取得し、`data/gnss_data.csv`に追加します。

## 機能

### 国内地震データ取得
- Yahoo!天気・災害の地震履歴一覧ページからデータを取得
- 既存の`data/2010-all.csv`と比較して新しいデータのみを追加
- 作業日の日付でフォルダを作成し、バックアップとログを保存
- 重複データの自動チェック

### 世界地震データ取得
- USGS Earthquake Catalog APIからデータを取得（マグニチュード6.0以上）
- 既存の`data/world-all.csv`の最新日付から自動的に開始日時を設定
- 既存データと比較して新しいデータのみを追加
- 作業日の日付でフォルダを作成し、バックアップとログを保存
- 重複データの自動チェック

### 深さデータ取得
- F-net（防災科研）からデータを取得（深さ300km以上）
- 直近2ヶ月のデータを自動的に取得
- 既存の`data/depth.csv`と比較して新しいデータのみを追加
- 作業日の日付でフォルダを作成し、バックアップとログを保存
- 重複データの自動チェック（既存データとの重複、取得データ内の重複）

## 必要なパッケージ

```bash
pip install requests beautifulsoup4 pandas lxml
```

または、プロジェクトルートの`requirements.txt`からインストール：

```bash
pip install -r requirements.txt
```

## 使い方

### バッチファイルで一括実行（推奨）

**最も簡単な方法**: バッチファイルをダブルクリックするだけです。

**方法1: プロジェクトルートから実行**
```
データ取得実行.bat をダブルクリック
```

**方法2: データ自動取得フォルダ内から実行**
```
データ自動取得\データ取得実行.bat をダブルクリック
```

このバッチファイルは以下の4つのスクリプトを順番に実行します：
1. 国内地震データ取得
2. 世界地震データ取得
3. 深さデータ取得
4. GNSSデータ取得

各スクリプトでエラーが発生した場合は、処理を中断してエラーメッセージを表示します。

### 国内地震データ取得

**方法1: データ自動取得フォルダ内から実行**
```bash
cd データ自動取得
python src/fetch_earthquake_data.py
```

**方法2: プロジェクトルートから実行（推奨）**
```bash
python fetch_earthquake_data.py
```

**デバッグモード**:
```bash
python fetch_earthquake_data.py --debug
```

### 世界地震データ取得

**方法1: データ自動取得フォルダ内から実行**
```bash
cd データ自動取得
python fetch_world_earthquake_data.py
```

**方法2: プロジェクトルートから実行（推奨）**
```bash
python fetch_world_earthquake_data.py
```

**デバッグモード**（直近7日間のデータのみ取得）:
```bash
python fetch_world_earthquake_data.py --debug
```

### 深さデータ取得

**方法1: データ自動取得フォルダ内から実行**
```bash
cd データ自動取得
python src/fetch_depth_data.py
```

**方法2: プロジェクトルートから実行（推奨）**
```bash
python fetch_depth_data.py
```

**デバッグモード**:
```bash
python fetch_depth_data.py --debug
```

**注意**: PowerShellで日本語パスが含まれる場合、エラーが発生する可能性があります。その場合は、`データ自動取得`フォルダに移動してから実行してください。

### 実行時の動作

#### 国内地震データ取得
1. **作業フォルダの作成**: 実行日の日付（例: `20251220`）でフォルダを作成
2. **既存データの読み込み**: `2010-all.csv`を読み込み
3. **データ取得**: Yahoo!天気・災害から最新の地震データを取得（最大10ページ）
4. **新しいデータの特定**: 既存データと比較して新しいデータのみを抽出
5. **バックアップ作成**: 既存データのバックアップを作業フォルダに保存
6. **データ追加**: 新しいデータを`2010-all.csv`に追加
7. **ログ保存**: 追加された新しいデータをログファイルとして保存

#### 世界地震データ取得
1. **作業フォルダの作成**: 実行日の日付（例: `20251220`）でフォルダを作成
2. **既存データの読み込み**: `world-all.csv`を読み込み
3. **開始日時の決定**: 既存データの最新日付の翌日を開始日時として設定
4. **データ取得**: USGS APIからマグニチュード6.0以上の地震データを取得
5. **新しいデータの特定**: 既存データと比較して新しいデータのみを抽出
6. **バックアップ作成**: 既存データのバックアップを作業フォルダに保存
7. **データ追加**: 新しいデータを`world-all.csv`に追加
8. **ログ保存**: 追加された新しいデータをログファイルとして保存

#### 深さデータ取得
1. **作業フォルダの作成**: 実行日の日付（例: `20251220`）でフォルダを作成
2. **既存データの読み込み**: `depth.csv`を読み込み
3. **対象月の決定**: 直近2ヶ月を自動的に決定
4. **データ取得**: F-netから各月のデータを取得（深さ300km以上のみ）
5. **新しいデータの特定**: 既存データと比較して新しいデータのみを抽出
6. **バックアップ作成**: 既存データのバックアップを作業フォルダに保存
7. **データ追加**: 新しいデータを`depth.csv`に追加
8. **ログ保存**: 追加された新しいデータをログファイルとして保存

## 出力ファイル

### 作業フォルダ（日付フォルダ）

実行日の日付で作成されるフォルダ内に以下が保存されます：

**国内地震データ取得**:
- `backup_YYYYMMDD_HHMMSS.csv`: 既存データのバックアップ
- `new_data_YYYYMMDD_HHMMSS.csv`: 追加された新しいデータのログ

**世界地震データ取得**:
- `world_backup_YYYYMMDD_HHMMSS.csv`: 既存データのバックアップ
- `world_new_data_YYYYMMDD_HHMMSS.csv`: 追加された新しいデータのログ

### メインデータファイル

- `2010-all.csv`: 国内地震データのメインファイル（更新される）
- `world-all.csv`: 世界地震データのメインファイル（更新される）

## データ形式

### 国内地震データ（2010-all.csv）

**入力データ（Yahoo!天気・災害）**:
- **日付**: "2025年12月20日 15時45分ごろ" → "2025/12/20"に変換
- **震源地**: 文字列（例: "青森県東方沖"）
- **マグニチュード**: 数値（例: 4.5）

**CSVファイル形式**:
```csv
date,place,magnitude
2025/12/20,青森県東方沖,4.4
2025/12/20,三陸沖,4.4
```

**重要**: 日付は必ず `YYYY/MM/DD` 形式で保存します。月と日は2桁にゼロ埋めします。

### 世界地震データ（world-all.csv）

**入力データ（USGS API）**:
- **日付**: ISO形式の日時 → "YYYY/MM/DD"形式に変換
- **震源地**: 文字列（例: "Japan", "Alaska"）
- **マグニチュード**: 数値（6.0以上）

**CSVファイル形式**:
```csv
date,place_w,magnitude_w
2025/12/20,Japan,6.7
2025/12/18,Alaska,6.0
```

### 深さデータ（depth.csv）

**入力データ（F-net）**:
- **日付**: テーブルから抽出 → "YYYY/MM/DD"形式に変換
- **深さ**: 数値（300km以上のみ）

**CSVファイル形式**:
```csv
date,depth
2025/12/20,350.5
2025/12/18,420.0
```

## ファイル整理について

フォルダ内のファイルを整理する場合は、以下のスクリプトを実行してください：

```bash
# ファイル整理スクリプトを実行
python organize_files.py
```

または、`整理実行.bat`をダブルクリックして実行することもできます。

このスクリプトは以下の作業を行います：
1. `src/`フォルダにソースファイルを移動
2. `data/`フォルダにデータファイルを移動
3. `debug/`フォルダにデバッグファイルを移動
4. 各スクリプトのパス設定を自動更新

## 注意事項

1. **レート制限**: サーバーに負荷をかけないよう、ページ取得の間に1秒待機します
2. **重複チェック**: 日付、震源地、マグニチュードの組み合わせで重複をチェックします
3. **エンコーディング**: CSVファイルはUTF-8（BOM付き）で保存されます
4. **エラーハンドリング**: ネットワークエラーやパースエラーが発生した場合、処理を中断します
5. **ファイル構成**: ファイル整理後は、各スクリプトのパス設定が自動的に更新されます

## トラブルシューティング

### データが取得できない場合

- インターネット接続を確認してください
- Yahoo!天気・災害のサイト構造が変更されていないか確認してください
- `max_pages`パラメータを調整してください

### 重複データが追加される場合

- 既存データの日付形式を確認してください（"12月20日"形式である必要があります）
- マグニチュードの精度（小数点以下）が一致しているか確認してください

## 今後の拡張予定

- スケジュール実行機能（タスクスケジューラ対応）
- エラーログの詳細化
- メール通知機能
